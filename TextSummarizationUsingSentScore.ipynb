{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzRxAbuKmbav"
      },
      "source": [
        "# NLP Project\r\n",
        "Text summarizer using frequency of words and calculating their sentence score\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfSgRBHd-5LJ"
      },
      "source": [
        "# Importing the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XLcvNB3_FWo",
        "outputId": "35074ee5-f278-4cc0-fde5-64e94b327e95"
      },
      "source": [
        "import bs4 as bs\r\n",
        "import urllib.request\r\n",
        "import re\r\n",
        "import nltk\r\n",
        "import heapq\r\n",
        "#nltk.download('punkt')\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eXDeAuP_KKn"
      },
      "source": [
        "# Fetching the data \r\n",
        "We will fetch our data by scraping the web and convert it into required format "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCkF7jkB_dy3"
      },
      "source": [
        "source = urllib.request.urlopen(\"https://en.wikipedia.org/wiki/Climate_change\").read()\r\n",
        "\r\n",
        "soup = bs.BeautifulSoup(source,'lxml')\r\n",
        "text = \"\"\r\n",
        "for paragraph in soup.find_all('p'):\r\n",
        "  text += paragraph.text"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XxB-2Q7_jOv"
      },
      "source": [
        "# Preprocessing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZukrEpnS_sFq"
      },
      "source": [
        "text = re.sub(r'\\[[0-9]*\\]',' ',text)\r\n",
        "text = re.sub(r'\\s+',' ',text)\r\n",
        "clean_text = text.lower()\r\n",
        "clean_text = re.sub(r'\\W',' ',clean_text)\r\n",
        "clean_text = re.sub(r'\\d',' ',clean_text)\r\n",
        "clean_text = re.sub(r'\\s+',' ',clean_text)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWMuUgZw_u2w"
      },
      "source": [
        "# Sentence Formation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMSu7RI9_52X"
      },
      "source": [
        "sentences = nltk.sent_tokenize(text)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMT2A1V0_864"
      },
      "source": [
        "# Stop words\r\n",
        "Downloading stopwords from nltk library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwBmkLqjAE9H"
      },
      "source": [
        "stop_words = nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2flbZEtOAJl3"
      },
      "source": [
        "# Creating Histogram and weighted Histogram\r\n",
        "We will calculate frequency of words using dictionary and also calculate weighted frequency by divding each term with highest frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdloNFdbAmG5"
      },
      "source": [
        "#creating histogram\r\n",
        "word2count = {}\r\n",
        "for word in nltk.word_tokenize(clean_text):\r\n",
        "  if word not in stop_words:\r\n",
        "    if word not in word2count.keys():\r\n",
        "      word2count[word] = 1\r\n",
        "    else:\r\n",
        "      word2count[word] += 1\r\n",
        "\r\n",
        "max_count = max(word2count.values())\r\n",
        "#weighted histogram\r\n",
        "word2countW = {}\r\n",
        "for key in word2count.keys():\r\n",
        "  word2countW[key] = word2count[key]/max_count"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF3jQQwqAqXA"
      },
      "source": [
        "# Calculating sentence score \r\n",
        "we will calculate the sentence score by adding weighted scores of each individual words present in weighted histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h6tM_MRBFUg"
      },
      "source": [
        "sent2score = {}\r\n",
        "for sentence in sentences:\r\n",
        "  for word in nltk.word_tokenize(sentence.lower()):\r\n",
        "    if word in word2countW.keys():\r\n",
        "      if len(sentence.split(' '))<25:\r\n",
        "        if sentence not in sent2score.keys():\r\n",
        "          sent2score[sentence] = word2countW[word]\r\n",
        "        else:\r\n",
        "          sent2score[sentence] += word2countW[word]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNXTcWJrBKEA"
      },
      "source": [
        "# Generating summary\r\n",
        "we will choose 5 sentences by sorting the sentences according to sentence score in descending order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00Hc4S7zBgw3",
        "outputId": "658c0e4b-6296-4800-ee78-cf1b26ff5819"
      },
      "source": [
        "summary = heapq.nlargest(5,sent2score,key= sent2score.get)\r\n",
        "i=1\r\n",
        "for sentence in summary:\r\n",
        "  print(f\"{i}.{sentence}\")\r\n",
        "  i +=1"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.Global warming usually refers to human-induced warming of the Earth system, whereas climate change can refer to natural as well as anthropogenic change.\n",
            "2. Climate change includes both the global warming driven by human emissions of greenhouse gases, and the resulting large-scale shifts in weather patterns.\n",
            "3.Geoengineering or climate engineering is the deliberate large-scale modification of the climate, considered a potential future method for counteracting climate change.\n",
            "4.The long-term effects of climate change include further ice melt, ocean warming, sea level rise, and ocean acidification.\n",
            "5.The attribution of climate change is the effort to scientifically show which mechanisms are responsible for observed changes in Earth's climate.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}